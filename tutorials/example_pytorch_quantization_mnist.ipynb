{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf96fb4",
   "metadata": {},
   "source": [
    "# Quantization using the Model Compression Toolkit - example in Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ed8f02",
   "metadata": {},
   "source": [
    "[Run this tutorial in Google Colab](https://colab.research.google.com/github/sony/model_optimization/blob/add_tf_notebook/tutorials/keras_notebook/keras_notebook.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822944a1",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743dbc3d",
   "metadata": {},
   "source": [
    "This quick start guide covers how to use the Model Compression Toolkit (MCT) for quantizing a PyTorch model. We will do so by giving an end-to-end example, training a model from scratch on MNIST data, then quantizing it using the MCT. Let us start with the relevant imports:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e2eeae",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf577a",
   "metadata": {},
   "source": [
    "In this tutorial we will cover:\n",
    "1. Training a Pytorch model from scratch on MNIST.\n",
    "2. Quantizing the model in a hardware-friendly manner (symmetric quantization, power-of-2 thresholds) using 8-bit activations and weights.\n",
    "3. We will examine the output quantized model, evaluate it and compare its performance to the original model.\n",
    "4. We will approximate the compression gains due to quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3396bf",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7690ef",
   "metadata": {},
   "source": [
    "Install the relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89e0bb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, http://piprep-ub18:8080/simple\n",
      "\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\n",
      "Collecting model-compression-toolkit\n",
      "  Downloading model_compression_toolkit-1.3.0-py3-none-any.whl (339 kB)\n",
      "\u001b[K     |████████████████████████████████| 339 kB 909 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (4.64.0)\n",
      "Requirement already satisfied: PuLP in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (2.6.0)\n",
      "Requirement already satisfied: scipy in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (3.5.1)\n",
      "Requirement already satisfied: scikit-image in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (0.19.2)\n",
      "Requirement already satisfied: tensorboard in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (2.8.0)\n",
      "Requirement already satisfied: numpy in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (1.22.3)\n",
      "Requirement already satisfied: networkx==2.5 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (2.5)\n",
      "Requirement already satisfied: scikit-learn in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (1.0.2)\n",
      "Requirement already satisfied: Pillow in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (9.1.0)\n",
      "Requirement already satisfied: opencv-python in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from model-compression-toolkit) (4.5.5.64)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from networkx==2.5->model-compression-toolkit) (5.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from matplotlib->model-compression-toolkit) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from matplotlib->model-compression-toolkit) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from matplotlib->model-compression-toolkit) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from matplotlib->model-compression-toolkit) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from matplotlib->model-compression-toolkit) (3.0.8)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from matplotlib->model-compression-toolkit) (4.32.0)\n",
      "Requirement already satisfied: six>=1.5 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->model-compression-toolkit) (1.16.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from scikit-image->model-compression-toolkit) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from scikit-image->model-compression-toolkit) (2022.4.8)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from scikit-image->model-compression-toolkit) (2.16.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from scikit-learn->model-compression-toolkit) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from scikit-learn->model-compression-toolkit) (3.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (3.3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (61.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (0.4.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (2.1.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (3.20.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (1.44.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from tensorboard->model-compression-toolkit) (1.8.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->model-compression-toolkit) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->model-compression-toolkit) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->model-compression-toolkit) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->model-compression-toolkit) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->model-compression-toolkit) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->model-compression-toolkit) (3.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->model-compression-toolkit) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->model-compression-toolkit) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->model-compression-toolkit) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->model-compression-toolkit) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard->model-compression-toolkit) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->model-compression-toolkit) (3.2.0)\n",
      "Installing collected packages: model-compression-toolkit\n",
      "Successfully installed model-compression-toolkit-1.3.0\n",
      "\u001b[33mWARNING: The repository located at piprep-ub18 is not a trusted or secure host and is being ignored. If this repository is available via HTTPS we recommend you use HTTPS instead, otherwise you may silence this warning and allow it anyway with '--trusted-host piprep-ub18'.\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, http://piprep-ub18:8080/simple\n",
      "Requirement already satisfied: torch in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (1.11.0+cu113)\n",
      "Requirement already satisfied: typing-extensions in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from torch) (4.1.1)\n",
      "Looking in indexes: https://pypi.org/simple, http://piprep-ub18:8080/simple\n",
      "Requirement already satisfied: torchvision in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (0.12.0+cu113)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from torchvision) (9.1.0)\n",
      "Requirement already satisfied: requests in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: numpy in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from torchvision) (4.1.1)\n",
      "Requirement already satisfied: torch==1.11.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from torchvision) (1.11.0+cu113)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests->torchvision) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Vols/vol_design/tools/swat/envs/liord/blog_post/lib/python3.8/site-packages (from requests->torchvision) (3.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install model-compression-toolkit\n",
    "! pip install torch \n",
    "! pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a82928d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DepthwiseConv2D is defined in hardware model, but is not used in framework hardware model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DepthwiseConv2D is defined in hardware model, but is not used in framework hardware model.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import model_compression_toolkit as mct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1653425b",
   "metadata": {},
   "source": [
    "## Train a Pytorch classifier model on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02312089",
   "metadata": {},
   "source": [
    "Let us define the network and some helper functions to train and evaluate the model. These are taken from the official Pytorch examples https://github.com/pytorch/examples/blob/main/mnist/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f9bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "random_seed = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "dataset_folder = '/Vols/vol_design/tools/swat/users/liord/datasets/mnist'\n",
    "epochs = 2\n",
    "gamma = 0.7\n",
    "lr = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d3c5a",
   "metadata": {},
   "source": [
    "Let us define the dataset loaders, and optimizer and train the model for 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c615a27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.275661\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.270859\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.122138\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.129065\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.147868\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.262936\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.105676\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.081128\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.091372\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.023000\n",
      "\n",
      "Test set: Average loss: 0.0470, Accuracy: 9847/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.025655\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.012885\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.109077\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.019512\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.082994\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.042370\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.255850\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.184586\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.033581\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.142920\n",
      "\n",
      "Test set: Average loss: 0.0349, Accuracy: 9884/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "dataset1 = datasets.MNIST(dataset_folder, train=True, download=True,\n",
    "                   transform=transform)\n",
    "dataset2 = datasets.MNIST(dataset_folder, train=False,\n",
    "                   transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, num_workers=1, pin_memory=True, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset2, num_workers=1, pin_memory=True,  batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69366614",
   "metadata": {},
   "source": [
    "After training for 2 epochs we get an accuracy of 98.84%. Not bad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd25a7",
   "metadata": {},
   "source": [
    "## Hardware-friendly quantization using MCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0321aad",
   "metadata": {},
   "source": [
    "Now we would like to quantize this model using the Model Compression Toolkit.\n",
    "To do so, we need to define a representative dataset, which is a function that returns a list of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "618975be",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_loader = iter(train_loader)\n",
    "\n",
    "def representative_data_gen() -> list:\n",
    "    return [next(image_data_loader)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a92bee",
   "metadata": {},
   "source": [
    "Now for the fireworks. Lets run hardware-friendly post training quantization on the model. The output of MCT is a simulated quantized model in the input model's framework. That is, the model adds fake-quantization nodes after layers that need to be quantized. The output model's size on the disk does'nt change, but all the quantization parameters are available for deployment on target hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63f695dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 14.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximated model size (in bytes): 1200584.0\n",
      "Approximated compression ratio: 3.998\n"
     ]
    }
   ],
   "source": [
    "quantized_model, quantization_info = mct.pytorch_post_training_quantization(\n",
    "    model, \n",
    "    representative_data_gen, \n",
    "    n_iter=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3521637",
   "metadata": {},
   "source": [
    "The MCT prints the approximated model size after real quantization and the compression ratio. In this example, we used the default setting of MCT and compressed the model from 32 bits to 8 bits, hence the compression ratio is x4. Using the simulated quantized model, we can evaluate its performance using the original model's testing environment, and compare its performance to the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f5fa4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<model_compression_toolkit.common.user_info.UserInformation object at 0x7f2ccd266d30>\n",
      "\n",
      "Test set: Average loss: 0.0331, Accuracy: 9879/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(quantization_info)\n",
    "test(quantized_model, device, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd09fa27",
   "metadata": {},
   "source": [
    "In this scenario, we see that the compression almost didn't affect the accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14877777",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e1572",
   "metadata": {},
   "source": [
    "In this tutorial, we demonstrated how to quantize a classification model for MNIST in a hardware-friendly manner using MCT. We saw that we can achieve an x4 compression ratio with minimal performance degradation. \n",
    "\n",
    "The advantage of quantizing in a hardware-friendly manner is that this model can run more efficiently in the sense of run time, power consumption, and memory on designated hardware. \n",
    "\n",
    "This is a very simple model and a very simple task. MCT can demonstrate competitive results on a wide variety of tasks and network architectures. Check out the paper for more details: https://arxiv.org/abs/2109.09113"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
